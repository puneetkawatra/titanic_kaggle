{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa9357f-f21d-4907-b3ec-454ceb4936fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    BaggingClassifier,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    #plot_confusion_matrix,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8788e8-e70d-4063-83fe-4d6fed7ce845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in training data\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0adf3ce8-c326-417e-9793-284ec55b019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb94c78-d833-45cc-b156-8b2121db89de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dean, Mr. Bertram Frank</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>C.A. 2315</td>\n",
       "      <td>20.5750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>373</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Beavan, Mr. William Thomas</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323951</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>477</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Renouf, Mr. Peter Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31027</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>598</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mr. Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>208</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Albimona, Mr. Nassef Cassem</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2699</td>\n",
       "      <td>18.7875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>848</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Markoff, Mr. Marin</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349213</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>553</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Brien, Mr. Timothy</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330979</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gustafsson, Mr. Johan Birger</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3101277</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>791</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Keane, Mr. Andrew \"Andy\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12460</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Glynn, Miss. Mary Agatha</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335677</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                          Name     Sex  \\\n",
       "93            94         0       3       Dean, Mr. Bertram Frank    male   \n",
       "372          373         0       3    Beavan, Mr. William Thomas    male   \n",
       "476          477         0       2       Renouf, Mr. Peter Henry    male   \n",
       "597          598         0       3           Johnson, Mr. Alfred    male   \n",
       "207          208         1       3   Albimona, Mr. Nassef Cassem    male   \n",
       "847          848         0       3            Markoff, Mr. Marin    male   \n",
       "552          553         0       3          O'Brien, Mr. Timothy    male   \n",
       "392          393         0       3  Gustafsson, Mr. Johan Birger    male   \n",
       "790          791         0       3      Keane, Mr. Andrew \"Andy\"    male   \n",
       "32            33         1       3      Glynn, Miss. Mary Agatha  female   \n",
       "\n",
       "      Age  SibSp  Parch     Ticket     Fare Cabin Embarked  \n",
       "93   26.0      1      2  C.A. 2315  20.5750   NaN        S  \n",
       "372  19.0      0      0     323951   8.0500   NaN        S  \n",
       "476  34.0      1      0      31027  21.0000   NaN        S  \n",
       "597  49.0      0      0       LINE   0.0000   NaN        S  \n",
       "207  26.0      0      0       2699  18.7875   NaN        C  \n",
       "847  35.0      0      0     349213   7.8958   NaN        C  \n",
       "552   NaN      0      0     330979   7.8292   NaN        Q  \n",
       "392  28.0      2      0    3101277   7.9250   NaN        S  \n",
       "790   NaN      0      0      12460   7.7500   NaN        Q  \n",
       "32    NaN      0      0     335677   7.7500   NaN        Q  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at subset of data\n",
    "train_data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9197f5e-2005-4c46-b7fe-a88f1ac3f074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows and columns\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d7f28cd-cfed-4eb1-ba55-20936c9394ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Information on each column\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff283367-520d-431f-a40b-6fbffad2039b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>891.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>446.0</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>223.5</td>\n",
       "      <td>446.0</td>\n",
       "      <td>668.5</td>\n",
       "      <td>891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>891.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>891.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>714.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20.125</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>891.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>891.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>891</td>\n",
       "      <td>681</td>\n",
       "      <td>347082</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>891.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9104</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>31.0</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>204</td>\n",
       "      <td>147</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>889</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count unique                      top freq       mean  \\\n",
       "PassengerId  891.0    NaN                      NaN  NaN      446.0   \n",
       "Survived     891.0    NaN                      NaN  NaN   0.383838   \n",
       "Pclass       891.0    NaN                      NaN  NaN   2.308642   \n",
       "Name           891    891  Braund, Mr. Owen Harris    1        NaN   \n",
       "Sex            891      2                     male  577        NaN   \n",
       "Age          714.0    NaN                      NaN  NaN  29.699118   \n",
       "SibSp        891.0    NaN                      NaN  NaN   0.523008   \n",
       "Parch        891.0    NaN                      NaN  NaN   0.381594   \n",
       "Ticket         891    681                   347082    7        NaN   \n",
       "Fare         891.0    NaN                      NaN  NaN  32.204208   \n",
       "Cabin          204    147                  B96 B98    4        NaN   \n",
       "Embarked       889      3                        S  644        NaN   \n",
       "\n",
       "                    std   min     25%      50%    75%       max  \n",
       "PassengerId  257.353842   1.0   223.5    446.0  668.5     891.0  \n",
       "Survived       0.486592   0.0     0.0      0.0    1.0       1.0  \n",
       "Pclass         0.836071   1.0     2.0      3.0    3.0       3.0  \n",
       "Name                NaN   NaN     NaN      NaN    NaN       NaN  \n",
       "Sex                 NaN   NaN     NaN      NaN    NaN       NaN  \n",
       "Age           14.526497  0.42  20.125     28.0   38.0      80.0  \n",
       "SibSp          1.102743   0.0     0.0      0.0    1.0       8.0  \n",
       "Parch          0.806057   0.0     0.0      0.0    0.0       6.0  \n",
       "Ticket              NaN   NaN     NaN      NaN    NaN       NaN  \n",
       "Fare          49.693429   0.0  7.9104  14.4542   31.0  512.3292  \n",
       "Cabin               NaN   NaN     NaN      NaN    NaN       NaN  \n",
       "Embarked            NaN   NaN     NaN      NaN    NaN       NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical description\n",
    "train_data.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7490c5cb-2bcb-4e36-adee-6586755c322e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin          687\n",
       "Age            177\n",
       "Embarked         2\n",
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values for each column\n",
    "train_data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa057d7-6514-429e-b569-c74cba11262a",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- Passenger ID is not required for prediction as it is not expected to be correlated to survival.\n",
    "- Most of the Cabin values are null, and this feature is not expected to contribute to prediction. Feature column will be dropped.\n",
    "- Name column is not expected to have any significant correlation with survival, and will be dropped.\n",
    "- Ticket number is a combination of string and numeric data. It will be split into two columns, one containing the string portion, and the other containing the numeric portion.\n",
    "- There are some missing values in Age and Embarked features, which will need treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a637a584-4065-4fb7-9105-88196265f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Ticket into a string and corresponding numeric column\n",
    "train_data[['Ticket_string', 'Ticket_num']] = train_data['Ticket'].str.extract(r'(.*?)(\\d+)$')\n",
    "train_data['Ticket_num'] = pd.to_numeric(train_data['Ticket_num'], errors='coerce')  # Coerce any non-numeric to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f981e6b-2180-4152-9bb3-c3ad0e3a1365",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data[\"Ticket_num\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f30d80e-3dcc-4620-b1bf-e98a490e4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_data[\"Ticket_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15645849-e00a-42f8-b1ab-e05b31baf23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop([\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"Ticket_string\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24da859-aeeb-4e8b-89b0-66dba2740517",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1cc544-bfa8-46d3-987a-f1a2aab768b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for class distribution\n",
    "round(train_data[\"Survived\"].value_counts(normalize=True)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323bc17f-8b08-460e-8d50-767cdceb72ba",
   "metadata": {},
   "source": [
    "_We see that the class is imbalanced._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9f298-deeb-4d32-9d23-1dfaa817d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_vars = [\"Age\",\"Fare\",\"Parch\",\"SibSp\",\"Ticket_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fdadfa-cd34-4865-818f-b781418b4ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = [\"Sex\",\"Pclass\",\"Embarked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01821381-bf5c-4816-b28d-29ca689cf9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[cont_vars].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd69ba1b-75ef-4166-9c87-d955511a4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in cat_vars:\n",
    "    print(f\"{var}:\",train_data[var].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4553fdfb-48d2-4da1-ad6a-7e34f7e40f75",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e35ccc0-1570-41cd-8c99-3f21e2eb1024",
   "metadata": {},
   "source": [
    "#### Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24cd532-9206-4328-bab7-f76904881f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot a boxplot and a histogram along the same scale.\n",
    "\n",
    "\n",
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12,7))\n",
    "    kde: whether to the show density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,  # Number of rows of the subplot grid= 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize,\n",
    "    )  # creating the 2 subplots\n",
    "    sns.boxplot(\n",
    "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
    "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
    "    sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
    "    ) if bins else sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
    "    )  # For histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
    "    )  # Add mean to the histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
    "    )  # Add median to the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c675c01-fa2a-42f3-96b9-1819006ceaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations on Passenger age\n",
    "histogram_boxplot(train_data,\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaced6b-fc7b-4c8a-ad8f-cdde57eea495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations on Passenger's ticket Fare\n",
    "histogram_boxplot(train_data,\"Fare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b913cecd-6f5f-4c1b-9f4b-aea69f350821",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ddeae-5a47-4ae9-af65-a98af5701e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data[\"Fare\"] > 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7493df-fd1e-4928-960e-b16093a9e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations on number of parents/children accompanying the passengers\n",
    "histogram_boxplot(train_data,\"Parch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3684dc0-9270-445e-8e34-a772d99eaf37",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5282717-64f7-46d1-b799-ea3a8209d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations on number of siblings/spouses accompanying the passengers\n",
    "histogram_boxplot(train_data,\"SibSp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f441890-7bd0-4f57-ad17-182c8cd59b09",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec4e9de-3b9b-4f6c-9c1c-3093c684fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations on numeric portion of the ticket number\n",
    "histogram_boxplot(train_data,\"Ticket_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c00dd0-5c62-4888-bdc9-cadb0bde654b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e7e05d9-800d-4903-a5d7-ba27a28f7d4a",
   "metadata": {},
   "source": [
    "#### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d6a5a4-f982-48d8-af4f-15ee3c9788db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create labeled barplots\n",
    "\n",
    "\n",
    "def labeled_barplot(data, feature, perc=False, n=None):\n",
    "    \"\"\"\n",
    "    Barplot with percentage at the top\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    perc: whether to display percentages instead of count (default is False)\n",
    "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(data[feature])  # length of the column\n",
    "    count = data[feature].nunique()\n",
    "    if n is None:\n",
    "        plt.figure(figsize=(count + 1, 5))\n",
    "    else:\n",
    "        plt.figure(figsize=(n + 1, 5))\n",
    "\n",
    "    plt.xticks(rotation=90, fontsize=15)\n",
    "    ax = sns.countplot(\n",
    "        data=data,\n",
    "        x=feature,\n",
    "        palette=\"Paired\",\n",
    "        hue=feature,\n",
    "        order=data[feature].value_counts().index[:n].sort_values(),\n",
    "    )\n",
    "\n",
    "    for p in ax.patches:\n",
    "        if perc == True:\n",
    "            label = \"{:.1f}%\".format(\n",
    "                100 * p.get_height() / total\n",
    "            )  # percentage of each class of the category\n",
    "        else:\n",
    "            label = p.get_height()  # count of each level of the category\n",
    "\n",
    "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
    "        y = p.get_height()  # height of the plot\n",
    "\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            (x, y),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            size=12,\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )  # annotate the percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac72003-d5a9-4f98-acba-82d01402ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observations on Survival Status\n",
    "labeled_barplot(train_data, \"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f033f-48b5-4629-b11a-e85ce39b36b8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2157eef-916d-4d85-af64-cd3ccabacd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observations on Passenger Sex\n",
    "labeled_barplot(train_data, \"Sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86402914-ea93-43b7-83ee-595b6cd5597a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae42044c-d591-48a2-81de-e7e1cc422348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observations on Passenger Class\n",
    "labeled_barplot(train_data, \"Pclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b280c4-5fcb-45ab-9253-c6a6ade1f743",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c627c-6c4b-4188-aa3d-a917af49879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observations on Passenger Port of Embarkation\n",
    "labeled_barplot(train_data, \"Embarked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f859a-e542-4b5f-b5a3-eb44b700171d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e4b13-bb8f-4570-b34e-22938fae333b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68621e06-391a-41ab-8887-10050616edbb",
   "metadata": {},
   "source": [
    "#### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1269643-29af-4d86-85d9-4e9856357941",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d21d05-cae4-44c9-ab6e-58a7bb876121",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (10, 7)})\n",
    "sns.boxplot(y=\"Age\", x=\"Sex\", data=train_data, orient=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68db2be-6626-4e4f-9f11-5b68940b04e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (10, 7)})\n",
    "sns.boxplot(y=\"Fare\", x=\"Sex\", data=train_data, orient=\"vertical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387460c4-997b-415e-aa2b-4d773a808c38",
   "metadata": {},
   "source": [
    "##### Continuous variables against target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76b8a18-23ff-405d-b829-f99c1469d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i,col in enumerate(cont_vars):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    sns.boxplot(x=\"Survived\",y=col,data=train_data)\n",
    "    plt.tight_layout()\n",
    "    plt.title(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf08ef-85ce-48a2-ab17-9ee8cc890718",
   "metadata": {},
   "source": [
    "##### Categorical variables against target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae46700a-d62f-4a17-af40-02aa0a4d4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot stacked bar chart\n",
    "\n",
    "\n",
    "def stacked_barplot(data, predictor, target):\n",
    "    \"\"\"\n",
    "    Print the category counts and plot a stacked bar chart\n",
    "\n",
    "    data: dataframe\n",
    "    predictor: independent variable\n",
    "    target: target variable\n",
    "    \"\"\"\n",
    "    count = data[predictor].nunique()\n",
    "    sorter = data[target].value_counts().index[-1]\n",
    "    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    print(tab1)\n",
    "    print(\"-\" * 120)\n",
    "    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 1, 5))\n",
    "    plt.legend(\n",
    "        loc=\"lower left\",\n",
    "        frameon=False,\n",
    "    )\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00bf3d5-cfb1-4440-9f55-49da596e59ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacked_barplot(train_data,\"Sex\",\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e2be4-4262-4b57-a436-468f33d3e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_barplot(train_data,\"Embarked\",\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a56e4-57f4-4787-9202-e9c31de2197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_barplot(train_data,\"Pclass\",\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f959510-6a63-4f86-8b6e-0f7bbc21a8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f91070-0f3e-4b06-beae-3ab20d2fc9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f48c7d3a-1730-44fa-8ac9-4a6ef53b73ac",
   "metadata": {},
   "source": [
    "#### Check for correlations amongst variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59666c5a-1472-4271-acc0-50e6b1b7304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_data,hue=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd339ea-1839-4e95-a0a8-02352e6ff3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f47b60b-e204-4106-8429-bb2f4efcb610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating target variable and other variables\n",
    "X = df.drop(\"Survived\",axis=1)\n",
    "y = df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701a74f5-3b7b-4f3e-bdc9-0962254a51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c143df6-e7f0-4c38-930d-bd4cee03824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_ratio = sum(1 for val in y if val == 1)/len(y)\n",
    "print(f\"Survival ratio: {survival_ratio:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f48b791-35db-4d90-9d53-311b64da012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.25, random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa97537-cb60-41a0-9684-862065222a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057743f-9823-46a1-b9ae-673b19e90a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_ratio_train = sum(1 for val in y_train if val == 1)/len(y_train)\n",
    "survival_ratio_val = sum(1 for val in y_val if val == 1)/len(y_val)\n",
    "print(f\"Survival ratio in training data: {survival_ratio_train:.2%}\")\n",
    "print(f\"Survival ratio in validation data: {survival_ratio_val:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8bf210-f0bd-43a3-801b-19859dbb545b",
   "metadata": {},
   "source": [
    "#### Pipeline (Column Transformation, One Hot Encoding, Imputation)\n",
    "\n",
    "* We will drop/modify columns to prepare for new data\n",
    "* We will perform one hot encoding on categorical variables\n",
    "* We will use median to impute missing values in Age column.\n",
    "* We will use most_frequent value to impute missing values in Embarked column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0ae8c-216f-42f0-8c84-1e027cb28e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef626533-79c2-4262-9f97-3d91adbd3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46ce61-cbfc-4658-aa80-e9889d30ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,columns_to_drop=[]):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # No fitting is required for dropping columns\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.columns_to_drop,axis=1)\n",
    "\n",
    "class ColumnSplitter(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self,column,new_columns,drop_columns=None,modify_column=None,modify_function=None):\n",
    "        self.column = column\n",
    "        self.new_columns = new_columns\n",
    "        self.drop_columns = drop_columns\n",
    "        self.modify_column = modify_column\n",
    "        self.modify_function = modify_function\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self  # No fitting is required for dropping columns\n",
    "\n",
    "    def transform(self,X):\n",
    "        X[self.new_columns] = X[self.column].str.extract(r'(.*?)(\\d+)$')\n",
    "        \n",
    "        if self.drop_columns:\n",
    "            X.drop(self.drop_columns,axis=1,inplace=True)\n",
    "        \n",
    "        if self.modify_column and self.modify_function:\n",
    "            X[self.modify_column] = X[self.modify_column].apply(self.modify_function)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbde906-0db5-4071-bd56-ae6660adf4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessors\n",
    "column_dropper = ColumnDropper(\n",
    "    columns_to_drop = [\"PassengerId\",\"Name\",\"Cabin\"]\n",
    ")\n",
    "\n",
    "column_splitter = ColumnSplitter(\n",
    "    column = \"Ticket\",\n",
    "    new_columns = [\"Ticket_string\",\"Ticket_num\"],\n",
    "    drop_columns = [\"Ticket_string\",\"Ticket\"],\n",
    "    modify_column = \"Ticket_num\",\n",
    "    modify_function = lambda x:pd.to_numeric(x, errors=\"coerce\") # Coerce any non-numeric to NaN\n",
    ")\n",
    "    \n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\",OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\",StandardScaler())\n",
    "    ])\n",
    "\n",
    "# Combine into ColumnTransformer\n",
    "\n",
    "col_transformers = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"cat\",categorical_transformer,cat_vars),\n",
    "        (\"num\",numerical_transformer,cont_vars),\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "preprocessor = Pipeline(steps = [\n",
    "    (\"drop\",column_dropper),\n",
    "    (\"split\",column_splitter),\n",
    "    (\"transformers\",col_transformers)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e8b999-43d7-4193-b560-8aefad17135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform on the training set, then transform on the validation set\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e855e-eb92-4bfd-bcd1-7c47434bd7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform on the training set, then transform on the validation set\n",
    "X_train_processed_2 = pd.DataFrame(preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0141df8-7bc9-4cee-8d1c-6174c825bcd1",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf42860-72bd-46f3-b902-7e273dbb55e2",
   "metadata": {},
   "source": [
    "#### Evaluation Method\n",
    "We will print multiple scores, but will compare accuracy for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fd6d87-3946-4b1d-9578-88c90b76c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
    "def model_performance_classification_sklearn(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check classification model performance\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "\n",
    "    # predicting using the independent variables\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
    "    recall = recall_score(target, pred)  # to compute Recall\n",
    "    precision = precision_score(target, pred)  # to compute Precision\n",
    "    f1 = f1_score(target, pred)  # to compute F1-score\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\n",
    "            \"Accuracy\": acc,\n",
    "            \"Recall\": recall,\n",
    "            \"Precision\": precision,\n",
    "            \"F1\": f1,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e9b992-058f-49a4-8be9-107a75593d38",
   "metadata": {},
   "source": [
    "#### Mulitple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c75ae6-527e-493e-ac36-ce6870d18326",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []  # Empty list to store all the models\n",
    "\n",
    "# Appending models into the list\n",
    "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
    "models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
    "models.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\n",
    "models.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\n",
    "models.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\n",
    "models.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n",
    "\n",
    "results = []  # Empty list to store all model's CV scores\n",
    "names = []  # Empty list to store name of the models\n",
    "\n",
    "\n",
    "# loop through all models to get the mean cross validated score\n",
    "print(\"\\n\" \"Cross-Validation Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    scoring = \"accuracy\"\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=5, shuffle=True, random_state=1\n",
    "    )  # Setting number of splits equal to 5\n",
    "    cv_result = cross_val_score(\n",
    "        estimator=model, X=X_train_processed, y=y_train, scoring=scoring, cv=kfold\n",
    "    )\n",
    "    results.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(\"{}: {}\".format(name, cv_result.mean() * 100))\n",
    "\n",
    "print(\"\\n\" \"Training Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    scores = accuracy_score(y_train, model.predict(X_train_processed)) * 100\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92087780-6029-45c4-8c7f-d63ece362df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
    "for name, model in models:\n",
    "    scores = accuracy_score(y_val, model.predict(X_val_processed)) * 100\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5eb4d-9d70-4fb6-a737-e01ba3426962",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f665e51-df66-46af-8278-1e4057042c4c",
   "metadata": {},
   "source": [
    "* XGBoost, Gradient Boost, and RandomForest are performing fairly well on validation dataset. We will select one bagging-based technique (RandomForest) and one boosting technique (XGBoost), which will be tuned further, to ensure better performance and avoid overfitting.\n",
    "* Let's start with RandomizedSearchCV to arrive at an approximate hyperparameter space and then use GridSearchCV to find the right parameters for best model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def472c-a8ae-42d0-aeeb-1680cd05840e",
   "metadata": {},
   "source": [
    "##### Let's tune Random forest using Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549aa3c-0a8f-4e60-90b5-65a6078c5abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Define a hyperparameter space\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 400, 500],  # Number of trees\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],        # Tree depth\n",
    "    'min_samples_split': [2, 5, 10, 20],            # Minimum samples to split\n",
    "    'min_samples_leaf': [1, 2, 4, 8],               # Minimum samples at leaf\n",
    "    'max_features': [0.3, 0.7, None],               # Number of features per split\n",
    "    'bootstrap': [True, False],                     # Bootstrap sampling\n",
    "    \"min_impurity_decrease\":[0.001, 0.002, 0.003],\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV\n",
    "random_search.fit(X_train_processed, y_train)\n",
    "\n",
    "# Get the best parameters from GridSearchCV\n",
    "print(\"Best Parameters from RandomizedSearchCV:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc69c77-93bb-4a16-8456-63f0167cc9c9",
   "metadata": {},
   "source": [
    "##### Let's fine tune Random Forest using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db6d6a-1a8d-4e28-80ee-01cd9c5a10a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a hyperparameter grid\n",
    "params = {\n",
    "    'n_estimators': [300, 400, 500],           # Number of trees\n",
    "    'max_depth': [20, 30, 40],                 # Tree depth\n",
    "    'min_samples_split': [5, 10, 15],            # Minimum samples to split\n",
    "    'min_samples_leaf': [1, 2, 4],              # Minimum samples at leaf\n",
    "    'max_features': [0.7, None],           # Number of features per split\n",
    "    'bootstrap': [True, False],                 # Bootstrap sampling\n",
    "    \"min_impurity_decrease\":[0.002, 0.003],\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=params,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "\n",
    "# Get the best parameters from GridSearchCV\n",
    "print(\"Best Parameters from GridSearchCV:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d05d0-81c1-455b-a412-b126d544c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tuned = grid_search.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "rf_tuned.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442437ba-b10e-4840-b2ee-7fb0b17591b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_classification_sklearn(rf_tuned,X_train_processed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859776d2-12fc-46c5-891f-a184ab51d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_classification_sklearn(rf_tuned,X_val_processed,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df80d3d-3a57-43d0-8bcb-6e1904e5943d",
   "metadata": {},
   "source": [
    "- We see some gap between training and validation set performance with these parameters.\n",
    "- Let's update some of those to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85aa8a5-9386-42a5-9b03-f98dc00dbea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters to reduce overfitting\n",
    "rf_tuned_2 = RandomForestClassifier(\n",
    "    max_features=0.7,\n",
    "    min_samples_leaf=4,\n",
    "    n_estimators=200,\n",
    "    random_state=1,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    bootstrap=True,\n",
    "    min_impurity_decrease=0.002,\n",
    ")\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "rf_tuned_2.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98afc8c4-9d71-44d3-89a5-b24212a93e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_classification_sklearn(rf_tuned_2,X_train_processed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c33d25-b614-48dd-a1ad-e0ce2c6a639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_classification_sklearn(rf_tuned_2,X_val_processed,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca48a9-0871-47a9-a0ff-d03bc269afc7",
   "metadata": {},
   "source": [
    "##### Let's tune XGBoost using Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc2775-5fc1-4c44-a85a-3cd1fdf6c59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model\n",
    "xgb = XGBClassifier(random_state=1, eval_metric=\"logloss\")\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_dist = {\n",
    "    \"n_estimators\": [50, 100, 150, 200, 250, 300],\n",
    "    \"scale_pos_weight\": [0, 1, 2, 3],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "    \"gamma\": [0, 3, 5],\n",
    "    \"subsample\": [0.5, 0.7, 0.9, 1.0],\n",
    "    \"colsample_bytree\":[0.5,0.7,0.9,1],\n",
    "    \"colsample_bylevel\":[0.5,0.7,0.9,1],\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00addce5-5e76-472d-8ef5-ba866e24319d",
   "metadata": {},
   "source": [
    "##### Let's fine tune XGBoost using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a062eb1-b95e-4400-af24-f005b51dcfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a hyperparameter grid\n",
    "params = {\n",
    "    \"n_estimators\": [150, 200, 250],\n",
    "    \"scale_pos_weight\": [0, 1, 2],\n",
    "    \"learning_rate\": [0.02, 0.05, 0.1],\n",
    "    \"gamma\": [0, 0.5, 1],\n",
    "    \"subsample\": [0.8, 0.9, 1.0],\n",
    "    \"colsample_bylevel\":[0.5,0.7],\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_obj = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=params,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV\n",
    "grid_obj.fit(X_train_processed, y_train)\n",
    "\n",
    "# Get the best parameters from GridSearchCV\n",
    "print(\"Best Parameters from GridSearchCV:\", grid_obj.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a5a8c-d11e-44c1-81ec-7ffd2b445efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the clf to the best combination of parameters\n",
    "xgb_tuned = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "xgb_tuned.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a4b960-ccfa-4ec6-b2b0-398aca8e6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_classification_sklearn(xgb_tuned,X_train_processed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9324bd-d470-47e3-baee-eacb3f32409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_classification_sklearn(xgb_tuned,X_val_processed,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828c6d75-b0fa-4076-8ea9-1ed3b2cd02f1",
   "metadata": {},
   "source": [
    "- We still see some gap between training and validation set performance with these parameters.\n",
    "- Let's add regularization and reduce learning rate to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1976ca9-876f-475a-bbdf-ceb7bb82eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters to reduce overfitting\n",
    "xgb_tuned_2 = XGBClassifier(\n",
    "    random_state = 1,\n",
    "    n_estimators = 150,\n",
    "    scale_pos_weight = 1,\n",
    "    learning_rate = 0.03,\n",
    "    gamma = 2,\n",
    "    subsample = 0.9,\n",
    "    colsample_bylevel = 0.5,\n",
    "    reg_lambda = 2\n",
    ")\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "xgb_tuned_2.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf00d9b-e8bd-4500-a632-851c77f15f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_classification_sklearn(xgb_tuned_2,X_train_processed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba24c46-a927-4851-bd7a-b0b649311c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_classification_sklearn(xgb_tuned_2,X_val_processed,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6e2b85-6f51-413c-92d0-0094403387a5",
   "metadata": {},
   "source": [
    "##### Let's attach feature names to the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad21f4f-de7f-4764-90b9-d61dcb2aaf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the initial columns after the column_dropper\n",
    "remaining_columns = X_train.drop(columns=[\"PassengerId\", \"Name\", \"Cabin\"]).columns.tolist()\n",
    "\n",
    "# Handle column_splitter transformation\n",
    "# Add new columns and remove dropped ones\n",
    "remaining_columns.remove(\"Ticket\")  # Drop 'Ticket'\n",
    "remaining_columns.append(\"Ticket_num\")  # Add 'Ticket_num'\n",
    "\n",
    "# Process categorical and numerical feature names\n",
    "\n",
    "# Fetch feature names from ColumnTransformer\n",
    "categorical_features = preprocessor.named_steps['transformers'].named_transformers_['cat'][\n",
    "    'encoder'\n",
    "].get_feature_names_out(cat_vars)  # Encoded feature names\n",
    "\n",
    "numerical_features = cont_vars  # Numerical features remain unchanged after scaling\n",
    "\n",
    "# Combine categorical and numerical features with passthrough columns\n",
    "passthrough_features = [\n",
    "    col for col in remaining_columns if col not in cat_vars + cont_vars\n",
    "]\n",
    "final_feature_names = list(categorical_features) + numerical_features + passthrough_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61384fc-eb21-43d8-ac30-b1430dd9de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = xgb_tuned_2.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "feature_names = list(final_feature_names)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='violet', align='center')\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e472da-c1c1-415c-8ecf-c9b3342bf43e",
   "metadata": {},
   "source": [
    "### Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f294c7-d96f-45db-a5bb-5aced90f601e",
   "metadata": {},
   "source": [
    "- Tuned XGBoost has the best performance amongst the two tuned models.\n",
    "- Passenger Sex, class and age are three most important features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de575d83-d59c-4fc8-ad42-fb1a9c6814b7",
   "metadata": {},
   "source": [
    "## Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d58aa-6120-4202-93a0-b2d36867b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b9aec-5d95-43c6-9ab4-c288f398a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_preprocessed = preprocessor.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd3d51-830b-4105-a36b-49a2ea3f1ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb_tuned.predict(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c0737c-f78e-4aee-b21f-9aacff339db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_data[\"PassengerId\"])\n",
    "test_df[\"Survived\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d2dd74-9e23-4fb4-9809-c26a03dd54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb6717a-735c-4939-aa33-b894f52c9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Survived\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f8fb99-e6a0-4d8b-9ddf-5be70c09a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d99d6-d8ab-48d1-94f0-ba88f1b6b8db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
